#!/bin/bash

#SBATCH --job-name=gedi_s5_ensemble
#SBATCH --output=logs/%j_gedi_s5_ensemble.txt
#SBATCH --error=logs/%j_gedi_s5_ensemble_error.txt
#SBATCH --time=0-2:00:00
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=8G
#SBATCH --gpus=1
#SBATCH --partition=gpu_amd

echo "üöÄ Starting GEDI Scenario 5 Ensemble Training"
echo "üìÖ Start time: $(date)"
echo "üñ•Ô∏è  Node: $(hostname)"
echo "üîß GPU: $CUDA_VISIBLE_DEVICES"

# Create log directory
mkdir -p chm_outputs/logs

# Activate environment
source chm_env/bin/activate

echo "üß† Training ensemble model combining GEDI pixel MLP (Scenario 4) and Google Embedding MLP (Scenario 1)..."

# Train ensemble model
python train_ensemble_mlp.py \
    --gedi-model-path chm_outputs/gedi_pixel_mlp_scenario4/gedi_pixel_mlp_scenario4_embedding_best.pth \
    --reference-model-path chm_outputs/production_mlp_reference_embedding_best.pth \
    --reference-height-path downloads/dchm_05LE4.tif \
    --output-dir chm_outputs/gedi_scenario5_ensemble \
    --patch-dir chm_outputs/ \
    --patch-pattern "*05LE4*embedding*" \
    --epochs 50 \
    --learning-rate 0.001 \
    --model-type simple \
    --gedi-model-type mlp \
    --band-selection embedding

echo "‚úÖ Ensemble training completed at $(date)"

# Check results
if [ -f "chm_outputs/gedi_scenario5_ensemble/ensemble_mlp_best.pth" ]; then
    echo "‚úÖ Ensemble model saved successfully"
    ls -la chm_outputs/gedi_scenario5_ensemble/
else
    echo "‚ùå Ensemble model not found"
    echo "Files in output directory:"
    ls -la chm_outputs/gedi_scenario5_ensemble/
fi
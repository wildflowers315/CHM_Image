# CHM Image Processing

A canopy height modeling for forest canopy height prediction from Google embedding and multi-modal satellite data using reference data and GEDI data in Hyogo, Tochigi and Kochi area in Japan.

## Features

### ğŸŒ² Multi-Modal Data Integration
- **Google Satellite Embedding v1**: 64-band multi-modal embedding (Sentinel-1/2, DEM, ALOS2, GEDI, ERA5, land cover) - **PRODUCTION READY**
- **Sentinel-1 SAR**: VV & VH polarizations with temporal time series support
- **Sentinel-2 Optical**: 10 bands with cloud masking and NDVI computation
- **ALOS-2 SAR**: L-band radar for structure information
- **GEDI LiDAR**: Sparse supervision for training and validation
- **DEM Data**: Topographic context (elevation, slope, aspect)
- **Auxiliary Globale Height data**: Global canopy height datasets (Potapov2021, Tolan2024, Lang2022, Pauls2024)

### ğŸ¤– Unified Model Architecture
- **Google Embedding MLP**: Neural networks optimized for 64-band embedding features (RÂ² = 0.8734, 73% improvement)
- **GEDI Ensemble Models**: Automated ensemble learning combining reference and GEDI supervision (RÂ² = 0.7762)
- **Random Forest & MLP**: Traditional models with temporal feature engineering
- **2D U-Net**: Spatial convolutional networks for non-temporal data
- **3D U-Net**: Temporal-spatial convolutional networks with 12-month time series
- **Shift-Aware U-Net**: Advanced 2D U-Net with GEDI geolocation compensation (88.0% training improvement)
- **Patch-based Training**: Consistent 256x256 pixels in 10m resolution (2.56km Ã— 2.56km) patch processing across all models

### ğŸš€ Advanced Training Features
- **Shift-Aware Supervision**: Compensates for GEDI geolocation uncertainties (25 shifts, Radius 2)
- **Data Augmentation**: 12x spatial transformations (3 flips Ã— 4 rotations)
- **Temporal Processing**: Automatic detection of temporal vs non-temporal data
- **Early Stopping**: Patience-based validation with model checkpointing
- **Multi-Patch Training**: Efficient batch processing for large-scale datasets
- **Enhanced Evaluation**: Comprehensive PDF reports with height-stratified analysis


## Installation

### ğŸ **Environment Setup** (Recommended)

```bash
# Create isolated Python virtual environment (Python 3.10+ required)
python3.10 -m venv chm_env
# Alternative: use system Python if 3.10+
# python -m venv chm_env

# Activate the virtual environment
source chm_env/bin/activate
# Upgrade pip to latest version
pip install --upgrade pip
# Install project dependencies
pip install -r requirements.txt

# Set up Google Earth Engine authentication
earthengine authenticate
```

### ğŸ”§ **Environment Management**
```bash
# Always activate environment before use
source chm_env/bin/activate 
# Deactivate when done
deactivate
```

## Quick Start

### ğŸ“¥ **Reference Data Download**
```bash
# Download reference height data for evaluation
### Tochigi
wget -O downloads/dchm_09gd4.tif https://www.geospatial.jp/ckan/dataset/f273c489-4a48-4c85-9f27-c6d82e1fb49c/resource/33f9c3e9-3773-4196-9f81-011eed50cf00/download/dchm_09gd4.tif

### Hyogo (Training Region)
wget -O downloads/dchm_05LE4.tif https://gic-hyogo.s3.ap-northeast-1.amazonaws.com/2023/rinya/dchm/dchm_05LE4.tif

### Kochi
wget -O downloads/dchm_04hf3.tif https://www.geospatial.jp/ckan/dataset/3e0eed6c-f709-4b47-bf1f-640303f1ef86/resource/51828f81-19ad-447d-8289-a79bb3ecc4b0/download/dchm_04hf3.tif
```

### ğŸ—ºï¸ **Create Area of Interest (AOI) from Reference Data**
```python
# Convert reference TIF file to GeoJSON for data collection
from utils import geotiff_to_geojson

# Create GeoJSON AOI from downloaded reference data
geojson_path = geotiff_to_geojson('downloads/dchm_09gd4.tif')
print(f"Created AOI: {geojson_path}")

# This creates downloads/dchm_09gd4.geojson with WGS84 polygon bounds
# Use this AOI file for Google Earth Engine data collection
```

**Alternative Command Line Usage:**
```bash
# Create AOI using Python directly
python -c "from utils import geotiff_to_geojson; geotiff_to_geojson('downloads/dchm_09gd4.tif')"

# Creates downloads/dchm_09gd4.geojson automatically
# Ready for use in chm_main.py --aoi parameter
```

**Function Details:**
- **Input**: Reference TIF file (any projection)
- **Output**: GeoJSON polygon file in WGS84 (EPSG:4326)
- **Usage**: Automatic reprojection and bounds extraction
- **Purpose**: Define study area for Google Earth Engine data collection


### ğŸš€ **Google Satellite Embedding Workflow**

#### 1. Data Collection via Google Earth Engine
```bash
# Authenticate with Google Earth Engine
earthengine authenticate

# Download Google Satellite Embedding patches (64-band multi-modal data)

bash sbatch/extract_embedding_patches_all_areas.sh

# Alternative
#  python chm_main.py \
#         --aoi downloads/dchm_05LE4.geojson \
#         --year 2022 \
#         --embedding-only \
#         --use-patches \
#         --export-patches \
#         --scale 10 \
#         --output-dir "outputs/embedding_patches" \
#         --patch-size 2560 \
#         --patch-overlap 10 \
#         --mask-type none

# This creates patches with pattern: *embedding*bandNum70*.tif (64 embedding + auxiliary bands) with 10 pixel overlap
```

#### 2. Train Google Embedding Model (Best Performance: RÂ² = 0.8734)

```bash
# Activate environment
source chm_env/bin/activate

# Train on 64-band Google Embedding data
python train_production_mlp.py \
  --band-selection embedding \
  --patch-dir chm_outputs/ \
  --reference-height-path downloads/dchm_05LE4.tif \
  --epochs 100 \
  --batch-size 32

# Model saved as: chm_outputs/production_mlp_reference_embedding_best.pth
```

#### 3. Cross-Region Prediction
```bash
# Predict on other regions using trained model
python predict_mlp_cross_region.py \
  --model-path chm_outputs/production_mlp_reference_embedding_best.pth \
  --band-selection embedding \
  --regions "04hf3,09gd4" \
  --output-dir chm_outputs/google_embedding_predictions/
```

#### 4. Advanced Ensemble Training (Best Cross-Region: RÂ² = 0.7762)
```bash
# Train automated ensemble with GEDI integration
python train_ensemble_mlp.py \
  --band-selection embedding \
  --patch-dir chm_outputs/ \
  --reference-height-path downloads/dchm_05LE4.tif \
  --epochs 50

# Model saved as: chm_outputs/gedi_scenario5_ensemble/ensemble_mlp_best.pth
```

## ğŸ–¥ï¸ **HPC Integration**: SLURM batch scripts for large-scale Google Embedding experiments (Scenarios 1-5)

### ğŸš€ **HPC Batch Execution Examples**

#### Complete Experimental Pipeline
```bash
# 1. Extract Google Embedding patches for all regions
sbatch sbatch/extract_embedding_patches_all_areas.sh

# 2. Train all scenarios with Google Embedding
# Scenario 1: Best individual model (RÂ² = 0.8734)
sbatch sbatch/train_google_embedding_scenario1.sh
# Scenario 1.5: GEDI-only shift-aware U-Net (prerequisite for Scenario 2A)
sbatch sbatch/train_google_embedding_scenario1_5.sh
# Scenario 2A: Ensemble of Scenario 1 + 1.5 (RÂ² = 0.7844)
sbatch sbatch/train_google_embedding_scenario2a.sh
# Scenario 4: GEDI pixel-level MLP (RÂ² = 0.1284)
sbatch sbatch/train_gedi_pixel_mlp_scenario4.sh
# Scenario 5: Ensemble of Scenario 1 + 4 (RÂ² = 0.7762, best cross-region)
sbatch sbatch/train_ensemble_scenario5.sh

# 3. Cross-region predictions by each model
sbatch sbatch/predict_google_embedding_scenario1.sh
sbatch sbatch/predict_google_embedding_scenario2a.sh
sbatch sbatch/predict_gedi_pixel_mlp_scenario4.sh
sbatch sbatch/predict_gedi_scenario5_ensemble.sh

# 4. Evaluation and comparison
sbatch sbatch/evaluate_google_embedding_scenario1.sh     # Scenario 1 predictions
sbatch sbatch/evaluate_google_embedding_scenario2a.sh    # Scenario 2A predictions
sbatch sbatch/evaluate_gedi_pixel_scenario4.sh           # Scenario 4 predictions
sbatch sbatch/evaluate_gedi_scenario5.sh                 # Scenario 5 predictions

# 5. Generate visualizations and final outputs
# Multi-scenario comparison plots for 4 scenario + global canopy heights
sbatch sbatch/create_gedi_scenario5_visualizations.sh

```

```bash
# Monitor job status
squeue -u $USER
```

### GEDI and Global height models correlation analysis with reference heights
- After extract csv, run following codes.
```bash
python analysis/add_reference_heights.py --csv chm_outputs/gedi_embedding_dchm_04hf3_DW_b83_2022_1m_scale10m_w3_All.csv
# output_path = os.path.join(csv_dir, f"{csv_name}_with_reference.csv") or custom --output csv_path.
```

```bash
# This gets all csv files in chm_outputs (default) with patterns; 
#      "*gedi_embedding*with_reference.csv",
#      "*gedi*reference*.csv"
python analysis/gedi_height_correlation_analysis.py
```


## Configuration

### ğŸ† **Model Performance Rankings** (Based on Comprehensive Testing)

**ğŸ¥‡ Google Satellite Embedding Models (RECOMMENDED):**
1. **Google Embedding Scenario 1**: RÂ² = 0.8734 (73% improvement over 30-band) â­â­â­ **OUTSTANDING**
2. **GEDI Scenario 5 Ensemble**: RÂ² = 0.7762 (best cross-region stability) â­â­â­ **PRODUCTION READY**
3. **Google Embedding Ensemble 2A**: RÂ² = 0.7844 (proven ensemble approach) â­â­â­ **STABLE**

**ğŸ¥ˆ Traditional Approaches:**
4. **GEDI Scenario 4 (Pixel)**: RÂ² = 0.1284 (challenging but provides insights) â­â­
5. **Original 30-band MLP**: RÂ² = 0.5026 (proven baseline) â­â­
6. **Shift-Aware U-Net**: 88.0% training improvement, 75.8% coverage â­â­

**ğŸ… Key Achievement**: Google Embedding models achieve **87% training accuracy** and **consistent cross-region performance** (-0.66 to -2.57 RÂ²) with automated ensemble learning.

### Key Parameters
```python
# Google Embedding Parameters (RECOMMENDED)
band_selection = 'embedding'  # Use 64-band Google Satellite Embedding v1
embedding_bands = 64  # A00-A63 multi-modal features
auxiliary_bands = 4-6  # Height products + forest mask
data_source = 'GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL'
normalization = [-1, 1]  # Pre-normalized range

# Data preparation parameters
year = '2022'
patch_size = 2560  # 2.56km patches (256x256 pixels at 10m)
patch_overlap = 0.0  # No overlap by default
scale = 10  # 10m resolution

# Training parameters (Google Embedding)
model_type = 'AdvancedReferenceHeightMLP'  # Optimized for embedding features
hidden_dims = [1024, 512, 256, 128, 64]  # Deep architecture
epochs = 100  # Sufficient for convergence
batch_size = 32  # Memory-efficient training
learning_rate = 0.001  # Stable convergence

# Traditional satellite parameters (fallback)
bands_satellite = 30  # Original Sentinel-1/2, DEM, climate
bands_temporal = 196  # 12-month time series
bands_non_temporal = 31  # Median composites
```

## Project Structure

```
CHM_Image/
â”œâ”€â”€ ğŸ“ Core Pipeline
â”‚   â”œâ”€â”€ chm_main.py                 # Google Earth Engine data collection
â”‚   â”œâ”€â”€ extract_gedi_with_embedding.py # Google Earth Engine data collection
â”‚   â”œâ”€â”€ train_predict_map.py        # Unified training and prediction system
â”‚   â”œâ”€â”€ predict.py                  # Primary prediction tool with mosaicking
â”‚   â””â”€â”€ run_main.py                 # Legacy main workflow
â”‚
â”œâ”€â”€ ğŸ“ Data Processing
â”‚   â”œâ”€â”€ data/                       # Data processing pipeline
â”‚   â”‚   â”œâ”€â”€ image_patches.py        # 3D patch creation and management
â”‚   â”‚   â”œâ”€â”€ normalization.py        # Band-specific normalization
â”‚   â”‚   â”œâ”€â”€ large_area.py          # Scalable regional processing
â”‚   â”‚   â”œâ”€â”€ multi_patch.py         # Multi-patch workflows
â”‚   â”‚   â””â”€â”€ patch_loader.py        # Efficient data loading
â”‚   â”œâ”€â”€ alos2_source.py            # ALOS-2 SAR data processing
â”‚   â”œâ”€â”€ sentinel1_source.py        # Sentinel-1 SAR processing
â”‚   â”œâ”€â”€ sentinel2_source.py        # Sentinel-2 optical processing
â”‚   â”œâ”€â”€ l2a_gedi_source.py         # GEDI LiDAR data handling
â”‚   â””â”€â”€ dem_source.py              # DEM processing utilities
â”‚
â”œâ”€â”€ ğŸ“ Models and Training
â”‚   â”œâ”€â”€ models/                     # Model architectures
â”‚   â”‚   â”œâ”€â”€ 3d_unet.py             # Primary 3D U-Net architecture
â”‚   â”‚   â”œâ”€â”€ unet_3d.py             # Alternative 3D U-Net
â”‚   â”‚   â”œâ”€â”€ trainers/              # Model-specific trainers
â”‚   â”‚   â””â”€â”€ losses/                # Loss function implementations
â”‚   â”œâ”€â”€ dl_models.py               # MLP and traditional models
â”‚   â””â”€â”€ training/                  # Modular training system (future)
â”‚       â”œâ”€â”€ core/                  # Base training infrastructure
â”‚       â”œâ”€â”€ data/                  # Data handling and augmentation
â”‚       â””â”€â”€ workflows/             # High-level training workflows
â”‚
â”œâ”€â”€ ğŸ“ Evaluation and Utilities
â”‚   â”œâ”€â”€ evaluate_google_embedding_scenario1.py # Metrics calculation
â”‚   â”œâ”€â”€ evaluate_google_embedding_scenario2a.py # Metrics calculation
â”‚   â”œâ”€â”€ create_simplified_prediction_visualizations.py # Visualization
â”‚   â”œâ”€â”€ evaluate_predictions.py    # Legacy metrics calculation
â”‚   â”œâ”€â”€ evaluate_temporal_results.py # Legacy Comprehensive PDF evaluation
â”‚   â”œâ”€â”€ save_evaluation_pdf.py     # Legacy report generation
â”‚   â”œâ”€â”€ utils/                     # Core utilities
â”‚   â”‚   â””â”€â”€ spatial_utils.py       # Enhanced spatial processing
â”‚   â”œâ”€â”€ config/                    # Configuration management
â”‚   â”‚   â””â”€â”€ resolution_config.py   # Multi-resolution support
â”‚   â””â”€â”€ raster_utils.py           # Raster processing utilities
â”‚
â”œâ”€â”€ ğŸ“ HPC Batch Processing (Google Embedding Experiments)
â”‚   â””â”€â”€ sbatch/                    # SLURM batch scripts for HPC execution
â”‚       â”œâ”€â”€ ğŸ“¥ Data Collection
â”‚       â”‚   â””â”€â”€ extract_embedding_patches_all_areas.sh    # Extract 64-band embedding patches (all 3 regions)
â”‚       â”œâ”€â”€ ğŸ‹ï¸ Training Scripts (Scenarios 1-5)
â”‚       â”‚   â”œâ”€â”€ train_google_embedding_scenario1.sh       # S1: Reference-only MLP (RÂ² = 0.8734)
â”‚       â”‚   â”œâ”€â”€ train_google_embedding_scenario1_5.sh     # S1.5: GEDI-only U-Net (prerequisite for S2A)
â”‚       â”‚   â”œâ”€â”€ train_google_embedding_scenario2a.sh      # S2A: Reference+GEDI ensemble (RÂ² = 0.7844)
â”‚       â”‚   â”œâ”€â”€ train_gedi_pixel_mlp_scenario4.sh         # S4: GEDI pixel MLP (RÂ² = 0.1284)
â”‚       â”‚   â””â”€â”€ train_ensemble_scenario5.sh               # S5: Best ensemble model (RÂ² = 0.7762)
â”‚       â”œâ”€â”€ ğŸ”® Prediction & Evaluation
â”‚       â”‚   â”œâ”€â”€ evaluate_google_embedding_scenario1.sh    # S1 cross-region predictions
â”‚       â”‚   â”œâ”€â”€ evaluate_google_embedding_scenario2a.sh   # S2A cross-region predictions
â”‚       â”‚   â”œâ”€â”€ evaluate_gedi_pixel_scenario4.sh          # S4 cross-region predictions
â”‚       â”‚   â”œâ”€â”€ evaluate_gedi_scenario5.sh                # S5 cross-region predictions
â”‚       â”‚   â””â”€â”€ compare_all_scenarios.sh                  # Multi-scenario performance analysis
â”‚       â””â”€â”€ ğŸ“Š Visualization Generation
â”‚           â”œâ”€â”€ create_simplified_visualizations.sh       # Multi-scenario comparison plots
â”‚           â””â”€â”€ create_gedi_scenario5_visualizations.sh   # GEDI ensemble specific outputs
â”‚
â”œâ”€â”€ ğŸ“ Development Files
â”‚   â””â”€â”€ docs/                      # Comprehensive documentation
â”‚       â”œâ”€â”€ docs/comprehensive_chm_experiment_summary.md
â”‚       â””â”€â”€ docs/gedi_pixel_extraction_and_evaluation_plan.md
â”‚
â””â”€â”€ ğŸ“ Configuration
    â”œâ”€â”€ requirements.txt           # Python dependencies
    â””â”€â”€ .gitignore                 # Git configuration
```

### Key Features by Directory

#### ğŸŒ² **Shift-Aware Training**: GEDI geolocation compensation with 88.0% improvement
#### ğŸ—ºï¸ **Comprehensive Mosaicking**: 75.8% coverage with 63-patch processing  
#### ğŸ¤– **Automatic Mode Detection**: Temporal vs non-temporal based on band patterns  
#### ğŸ¯ **Sparse GEDI Supervision**: <0.3% pixel coverage handled efficiently
#### ğŸ”„ **Intelligent Fallbacks**: 3D U-Net falls back to temporal averaging when needed
#### ğŸ“Š **Production Ready**: Fully documented and tested pipeline

## Dependencies

### Core Requirements
- **Python 3.10.0+** (tested with Python 3.10.0)
- **Google Earth Engine Python API** (earthengine-api)
- **PyTorch** (for U-Net models with CUDA support)
- **Rasterio** (geospatial raster processing)
- **NumPy & Pandas** (data processing)
- **scikit-learn** (RF/MLP models)

### Specialized Libraries  
- **rasterio[merge]** (spatial mosaicking)
- **geopandas** (vector data handling)
- **matplotlib & reportlab** (evaluation reports)
- **tqdm** (progress bars)
- **shapely** (geometric operations)

### GPU Requirements
- **CUDA-enabled PyTorch**: **ESSENTIAL** for efficient training and prediction
  - **Training**: Google Embedding models require GPU for reasonable training times (10 min vs 2+ hours on CPU)
  - **Prediction**: Cross-region prediction benefits significantly from GPU acceleration


### Optional Enhancements
- **Mixed precision training** (automatic mixed precision support for faster training)


## Data Requirements

### Input Data
- **Area of Interest (AOI)**: GeoJSON format defining study area
- **Google Satellite Embedding v1**: 64-band multi-modal embedding via Google Earth Engine (`GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL`)
- **GEDI L2A**: Sparse LiDAR heights for training/validation (<0.3% coverage)
- **Reference CHM**: Ground truth data for evaluation
- **Auxiliary Height Products**: Global canopy height datasets (Potapov2021, Tolan2024, Lang2022, Pauls2024)

### Satellite Data (via Google Earth Engine)

**ğŸ¥‡ Google Satellite Embedding v1 (RECOMMENDED):**
- **Data Source**: `GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL`
- **Features**: 64 bands (A00-A63) combining multiple satellite sources
- **Resolution**: 10m, pre-normalized [-1, 1] range
- **Components**: Sentinel-1/2, DEM, ALOS2, GEDI, ERA5, land cover
- **Usage**: `--band-selection embedding` or `--embedding-mode`
- **Performance**: RÂ² = 0.8734 (73% improvement over traditional approaches)

**ğŸ¥ˆ Traditional Satellite Data (Fallback):**
- **Sentinel-1**: C-band SAR (VV & VH polarizations)
  - Non-temporal: Median composite (2 bands)
  - Temporal: 12-month time series (24 bands)
- **Sentinel-2**: Optical imagery (10 bands + NDVI)
  - Non-temporal: Cloud-free composite (11 bands)  
  - Temporal: Monthly composites (132 bands)
- **ALOS-2**: L-band SAR data
  - Non-temporal: Median composite (2 bands)
  - Temporal: 12-month series (24 bands)
- **DEM**: Elevation, slope, aspect (~5 bands)
- **Forest Mask**: Forest masking such as DW or NDVI


## Expected Output Structure
```
chm_outputs/
â”œâ”€â”€ ğŸ† Google Embedding Models (RECOMMENDED)
â”‚   â”œâ”€â”€ production_mlp_reference_embedding_best.pth        # Google Embedding MLP (RÂ² = 0.8734)
â”‚   â”œâ”€â”€ gedi_scenario5_ensemble/ensemble_mlp_best.pth      # GEDI Ensemble (RÂ² = 0.7762)
â”‚   â”œâ”€â”€ google_embedding_scenario2a/        
â”‚   â”‚     â”œâ”€â”€ ensemble_model/ensemble_mlp_best.pth         # Ensemble 2A (RÂ² = 0.7844)
â”‚   â”‚     â””â”€â”€ gedi_unet_model/shift_aware_unet_r2.pth
â”‚   â””â”€â”€ gedi_pixel_mlp_scenario4/                          # GEDI Pixel Model (RÂ² = 0.1284)
â”‚         â””â”€â”€ gedi_pixel_mlp_scenario4_embedding_best.pth
â”œâ”€â”€ ğŸ“Š Predictions
â”‚   â”œâ”€â”€ google_embedding_scenario1_predictions/            # Best individual model predictions
â”‚   â”œâ”€â”€ gedi_scenario5_predictions/                        # Best ensemble predictions  
â”‚   â”œâ”€â”€ google_embedding_scenario2a_predictions/           # Stable ensemble predictions
â”‚   â””â”€â”€ cross_region_predictions/                          # Traditional 30-band predictions
â”œâ”€â”€ ğŸ“ˆ Evaluation & Visualization
â”‚   â”œâ”€â”€ simplified_prediction_visualizations/              # Multi-scenario comparisons
â”‚   â””â”€â”€ gedi_scenario5_visualizations/                     # GEDI ensemble visualizations
â”œâ”€â”€ ğŸ”§ Traditional Models (Fallback)
â”‚   â””â”€â”€ production_mlp_best.pth                           # Original 30-band MLP
â””â”€â”€ ğŸ“ Extracted data (Image patches and csv) through GEE
    â”œâ”€â”€ dchm_{region_id}_bandNum*.tif                     # Patch TIF files for 30 bands + GEDI
    â”œâ”€â”€ dchm_{region_id}_embedding_bandNum*.tif           # Patch TIF files for google embedding
    â””â”€â”€ gedi_embedding_dchm_{region_id}*.csv              # GEDI pixel data with google embedding
       â””â”€â”€*with_reference.csv                             # Add reference_heights by `analysis/add_reference_heights.py`
```

## ğŸ“Š **Performance Comparison Summary**

| Approach | Data Type | Training RÂ² | Cross-Region RÂ² | Status | Key Advantage |
|----------|-----------|-------------|-----------------|--------|---------------|
| **Google Embedding Scenario 1** | 64-band | **0.8734** | -1.68 | âœ… Outstanding | Maximum training accuracy |
| **GEDI Scenario 5 Ensemble** | 64-band | **0.7762** | **-0.66 to -2.57** | âœ… **Best Cross-Region** | Automated ensemble learning |
| **Google Embedding Ensemble 2A** | 64-band | 0.7844 | -0.91 to -3.12 | âœ… Proven | Most consistent correlations |
| **GEDI Scenario 4 (Pixel)** | 64-band | 0.1284 | -0.39 to -1.32 | âš ï¸ Mixed | Better RMSE, challenging correlations |
| **Original 30-band MLP** | 30-band | 0.5026 | -26.58 | âœ… Production | Proven baseline with bias correction |
| **Shift-Aware U-Net** | Various | N/A | N/A | âœ… Alternative | 88% improvement for specific use cases |

### ğŸ“ˆ **Cross-Region Generalization**
- **Best Immediate Deployment**: Global products (Potapov2021: RÂ² = -0.39 to -0.55)
- **Best with Local Training**: Our models (GEDI Scenario 5: RÂ² = 0.7762 training, -0.66 to -2.57 cross-region)
- **Key Finding**: Our models excel with training data; global products better for immediate cross-region deployment
- **Bias Correction**: Essential for cross-region deployment (Kochi: 2.5x, Tochigi: 3.7x factors)


## Legacy Code
### Traditional 4-Step Pipeline
```bash
# Use 10 pixel overlap which is defaults
python chm_main.py --aoi downloads/dchm_05LE4.geojson --year 2022 --use-patches --export-patches
# Use 20 pixel overlap
# python chm_main.py --aoi downloads/dchm_05LE4.geojson --year 2022 --use-patches --export-patches --patch-overlap 20
```

```bash
# Complete workflow with area of interest
python run_main.py \
  --aoi_path downloads/dchm_09gd4.geojson \
  --year 2022 \
  --eval_tif_path downloads/dchm_09gd4.tif \
  --use-patches \
  --patch-size 2560 \
  --model 3d_unet \
  --steps data_preparation height_analysis train_predict evaluate

# Temporal mode (Paul's 2025 methodology)
python run_main.py --temporal-mode --monthly-composite median --steps data_preparation
```

### Unified Patch-Based Training
```bash
# Shift-aware U-Net (RECOMMENDED - best performance)
python train_predict_map.py \
  --patch-dir "chm_outputs/" \
  --model shift_aware_unet \
  --output-dir chm_outputs/shift_aware_results \
  --shift-radius 2 \
  --epochs 50 \
  --learning-rate 0.0001 \
  --batch-size 2 \
  --generate-prediction

# Traditional Random Forest
python train_predict_map.py \
  --patch-path "chm_outputs/dchm_09gd4_bandNum31_scale10_patch0000.tif" \
  --model rf \
  --output-dir chm_outputs/rf_results

# Temporal 3D U-Net with data augmentation
python train_predict_map.py \
  --patch-path "chm_outputs/dchm_09gd4_temporal_bandNum196_scale10_patch0000.tif" \
  --model 3d_unet \
  --output-dir chm_outputs/3d_unet_results \
  --augment \
  --early-stopping-patience 15 \
  --generate-prediction
```

### Multi-Patch Processing
```bash
# Process all patches in a directory
python train_predict_map.py \
  --patch-dir "chm_outputs/" \
  --model-path "chm_outputs/2d_unet/best_model.pth" \
  --model 2d_unet \
  --mode predict \
  --generate-prediction

# Create spatial mosaic from predictions
python predict.py \
  --patch-dir "chm_outputs/" \
  --model-path "chm_outputs/3d_unet/final_model.pth" \
  --output-path "chm_outputs/merged_prediction.tif"
```

### Workflow Steps with Legacy code
#### 1. Data Preparation
```bash
python run_main.py --steps data_preparation
```
- Downloads satellite data from Google Earth Engine
- Processes multi-temporal Sentinel-1, Sentinel-2, and ALOS-2 data
- Creates forest mask using WorldCover data
- Exports patch-based training data with automatic temporal/non-temporal detection

#### 2. Height Analysis  
```bash
python run_main.py --steps height_analysis
```
- Combines GEDI height data with satellite features
- Analyzes temporal patterns and height distributions
- Generates comprehensive height statistics

#### 3. Training and Prediction
```bash
python run_main.py --steps train_predict
```
- Unified training for all model types (RF, MLP, 2D U-Net, 3D U-Net)
- Automatic temporal/non-temporal mode detection
- Enhanced training with data augmentation and early stopping
- Generates full spatial prediction maps

#### 4. Evaluation
```bash
python run_main.py --steps evaluate
```
- Comprehensive model performance evaluation
- Height-stratified analysis (critical for tall tree performance)
- Multi-page PDF reports with visualizations
- Feature importance and spatial distribution analysis


## License

This project is licensed under the MIT License - see the LICENSE file for details.
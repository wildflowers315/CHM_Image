# CHM Image Processing

A canopy height modeling for forest canopy height prediction from Google embedding and multi-modal satellite data using reference data and GEDI data in Hyogo, Tochigi and Kochi area in Japan.

## Features

### üå≤ Multi-Modal Data Integration
- **Google Satellite Embedding v1**: 64-band multi-modal embedding (Sentinel-1/2, DEM, ALOS2, GEDI, ERA5, land cover) - **PRODUCTION READY**
- **Sentinel-1 SAR**: VV & VH polarizations with temporal time series support
- **Sentinel-2 Optical**: 10 bands with cloud masking and NDVI computation
- **ALOS-2 SAR**: L-band radar for structure information
- **GEDI LiDAR**: Sparse supervision for training and validation
- **DEM Data**: Topographic context (elevation, slope, aspect)
- **Auxiliary Globale Height data**: Global canopy height datasets (Potapov2021, Tolan2024, Lang2022, Pauls2024)

### ü§ñ Unified Model Architecture
- **Google Embedding MLP**: Neural networks optimized for 64-band embedding features (R¬≤ = 0.8734, 73% improvement)
- **GEDI Ensemble Models**: Automated ensemble learning combining reference and GEDI supervision (R¬≤ = 0.7762)
- **Random Forest & MLP**: Traditional models with temporal feature engineering
- **2D U-Net**: Spatial convolutional networks for non-temporal data
- **3D U-Net**: Temporal-spatial convolutional networks with 12-month time series
- **Shift-Aware U-Net**: Advanced 2D U-Net with GEDI geolocation compensation (88.0% training improvement)
- **Patch-based Training**: Consistent 256x256 pixels in 10m resolution (2.56km √ó 2.56km) patch processing across all models

### üöÄ Advanced Training Features
- **Shift-Aware Supervision**: Compensates for GEDI geolocation uncertainties (25 shifts, Radius 2)
- **Data Augmentation**: 12x spatial transformations (3 flips √ó 4 rotations)
- **Temporal Processing**: Automatic detection of temporal vs non-temporal data
- **Early Stopping**: Patience-based validation with model checkpointing
- **Multi-Patch Training**: Efficient batch processing for large-scale datasets
- **Enhanced Evaluation**: Comprehensive PDF reports with height-stratified analysis


## Installation

### üêç **Environment Setup** (Recommended)

```bash
# Create isolated Python virtual environment (Python 3.10+ required)
python3.10 -m venv chm_env
# Alternative: use system Python if 3.10+
# python -m venv chm_env

# Activate the virtual environment
source chm_env/bin/activate
# Upgrade pip to latest version
pip install --upgrade pip
# Install project dependencies
pip install -r requirements.txt

# Set up Google Earth Engine authentication
earthengine authenticate
```

### üîß **Environment Management**
```bash
# Always activate environment before use
source chm_env/bin/activate 
# Deactivate when done
deactivate
```

## Quick Start

### üì• **Reference Data Download**
```bash
# Download reference height data for evaluation
### Tochigi
wget -O downloads/dchm_09gd4.tif https://www.geospatial.jp/ckan/dataset/f273c489-4a48-4c85-9f27-c6d82e1fb49c/resource/33f9c3e9-3773-4196-9f81-011eed50cf00/download/dchm_09gd4.tif

### Hyogo (Training Region)
wget -O downloads/dchm_05LE4.tif https://gic-hyogo.s3.ap-northeast-1.amazonaws.com/2023/rinya/dchm/dchm_05LE4.tif

### Kochi
wget -O downloads/dchm_04hf3.tif https://www.geospatial.jp/ckan/dataset/3e0eed6c-f709-4b47-bf1f-640303f1ef86/resource/51828f81-19ad-447d-8289-a79bb3ecc4b0/download/dchm_04hf3.tif
```

### üó∫Ô∏è **Create Area of Interest (AOI) from Reference Data**
```python
# Convert reference TIF file to GeoJSON for data collection
from utils import geotiff_to_geojson

# Create GeoJSON AOI from downloaded reference data
geojson_path = geotiff_to_geojson('downloads/dchm_09gd4.tif')
print(f"Created AOI: {geojson_path}")

# This creates downloads/dchm_09gd4.geojson with WGS84 polygon bounds
# Use this AOI file for Google Earth Engine data collection
```

**Alternative Command Line Usage:**
```bash
# Create AOI using Python directly
python -c "from utils import geotiff_to_geojson; geotiff_to_geojson('downloads/dchm_09gd4.tif')"

# Creates downloads/dchm_09gd4.geojson automatically
# Ready for use in chm_main.py --aoi parameter
```

**Function Details:**
- **Input**: Reference TIF file (any projection)
- **Output**: GeoJSON polygon file in WGS84 (EPSG:4326)
- **Usage**: Automatic reprojection and bounds extraction
- **Purpose**: Define study area for Google Earth Engine data collection


### üöÄ **Google Satellite Embedding Workflow**

#### 1. Data Collection via Google Earth Engine
```bash
# Authenticate with Google Earth Engine
earthengine authenticate

# Download Google Satellite Embedding patches (64-band multi-modal data)

bash sbatch/extract_embedding_patches_all_areas.sh

# Alternative
#  python chm_main.py \
#         --aoi downloads/dchm_05LE4.geojson \
#         --year 2022 \
#         --embedding-only \
#         --use-patches \
#         --export-patches \
#         --scale 10 \
#         --output-dir "outputs/embedding_patches" \
#         --patch-size 2560 \
#         --patch-overlap 10 \
#         --mask-type none

# This creates patches with pattern: *embedding*bandNum70*.tif (64 embedding + auxiliary bands) with 10 pixel overlap
```

#### 2. Train Google Embedding Model (Best Performance: R¬≤ = 0.8734)

```bash
# Activate environment
source chm_env/bin/activate

# Train on 64-band Google Embedding data
python train_production_mlp.py \
  --band-selection embedding \
  --patch-dir chm_outputs/ \
  --reference-height-path downloads/dchm_05LE4.tif \
  --epochs 100 \
  --batch-size 32

# Model saved as: chm_outputs/production_mlp_reference_embedding_best.pth
```

#### 3. Cross-Region Prediction
```bash
# Predict on other regions using trained model
python predict_mlp_cross_region.py \
  --model-path chm_outputs/production_mlp_reference_embedding_best.pth \
  --band-selection embedding \
  --regions "04hf3,09gd4" \
  --output-dir chm_outputs/google_embedding_predictions/
```

#### 4. Advanced Ensemble Training (Best Cross-Region: R¬≤ = 0.7762)
```bash
# Train automated ensemble with GEDI integration
python train_ensemble_mlp.py \
  --band-selection embedding \
  --patch-dir chm_outputs/ \
  --reference-height-path downloads/dchm_05LE4.tif \
  --epochs 50

# Model saved as: chm_outputs/gedi_scenario5_ensemble/ensemble_mlp_best.pth
```

## üñ•Ô∏è **HPC Integration**: SLURM batch scripts for large-scale Google Embedding experiments (Scenarios 1-5)

### üöÄ **HPC Batch Execution Examples**

#### Complete Experimental Pipeline
```bash
# 1. Extract Google Embedding patches for all regions
sbatch sbatch/extract_embedding_patches_all_areas.sh

# 2. Train all scenarios with Google Embedding
# Scenario 1: Best individual model (R¬≤ = 0.8734)
sbatch sbatch/train_google_embedding_scenario1.sh
# Scenario 1.5: GEDI-only shift-aware U-Net (prerequisite for Scenario 2A)
sbatch sbatch/train_google_embedding_scenario1_5.sh
# Scenario 2A: Ensemble of Scenario 1 + 1.5 (R¬≤ = 0.7844)
sbatch sbatch/train_google_embedding_scenario2a.sh
# Scenario 4: GEDI pixel-level MLP (R¬≤ = 0.1284)
sbatch sbatch/train_gedi_pixel_mlp_scenario4.sh
# Scenario 5: Ensemble of Scenario 1 + 4 (R¬≤ = 0.7762, best cross-region)
sbatch sbatch/train_ensemble_scenario5.sh

# 3. Cross-region predictions by each model
sbatch sbatch/predict_google_embedding_scenario1.sh
sbatch sbatch/predict_google_embedding_scenario2a.sh
sbatch sbatch/predict_gedi_pixel_mlp_scenario4.sh
sbatch sbatch/predict_gedi_scenario5_ensemble.sh

# 4. Evaluation and comparison
sbatch sbatch/evaluate_google_embedding_scenario1.sh     # Scenario 1 predictions
sbatch sbatch/evaluate_google_embedding_scenario2a.sh    # Scenario 2A predictions
sbatch sbatch/evaluate_gedi_pixel_scenario4.sh           # Scenario 4 predictions
sbatch sbatch/evaluate_gedi_scenario5.sh                 # Scenario 5 predictions

# 5. Generate visualizations and final outputs
# Multi-scenario comparison plots for 4 scenario + global canopy heights
sbatch sbatch/create_gedi_scenario5_visualizations.sh

```

```bash
# Monitor job status
squeue -u $USER
```

### GEDI and Global height models correlation analysis with reference heights
- After extract csv, run following codes.
```bash
python analysis/add_reference_heights.py --csv chm_outputs/gedi_embedding_dchm_04hf3_DW_b83_2022_1m_scale10m_w3_All.csv
# output_path = os.path.join(csv_dir, f"{csv_name}_with_reference.csv") or custom --output csv_path.
```

```bash
# This gets all csv files in chm_outputs (default) with patterns; 
#      "*gedi_embedding*with_reference.csv",
#      "*gedi*reference*.csv"
python analysis/gedi_height_correlation_analysis.py
```


## Configuration

### üèÜ **Model Performance Rankings** (Based on Comprehensive Testing)

**ü•á Google Satellite Embedding Models (RECOMMENDED):**
1. **Google Embedding Scenario 1**: R¬≤ = 0.8734 (73% improvement over 30-band) ‚≠ê‚≠ê‚≠ê **OUTSTANDING**
2. **GEDI Scenario 5 Ensemble**: R¬≤ = 0.7762 (best cross-region stability) ‚≠ê‚≠ê‚≠ê **PRODUCTION READY**
3. **Google Embedding Ensemble 2A**: R¬≤ = 0.7844 (proven ensemble approach) ‚≠ê‚≠ê‚≠ê **STABLE**

**ü•à Traditional Approaches:**
4. **GEDI Scenario 4 (Pixel)**: R¬≤ = 0.1284 (challenging but provides insights) ‚≠ê‚≠ê
5. **Original 30-band MLP**: R¬≤ = 0.5026 (proven baseline) ‚≠ê‚≠ê
6. **Shift-Aware U-Net**: 88.0% training improvement, 75.8% coverage ‚≠ê‚≠ê

**üèÖ Key Achievement**: Google Embedding models achieve **87% training accuracy** and **consistent cross-region performance** (-0.66 to -2.57 R¬≤) with automated ensemble learning.

### Key Parameters
```python
# Google Embedding Parameters (RECOMMENDED)
band_selection = 'embedding'  # Use 64-band Google Satellite Embedding v1
embedding_bands = 64  # A00-A63 multi-modal features
auxiliary_bands = 4-6  # Height products + forest mask
data_source = 'GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL'
normalization = [-1, 1]  # Pre-normalized range

# Data preparation parameters
year = '2022'
patch_size = 2560  # 2.56km patches (256x256 pixels at 10m)
patch_overlap = 0.0  # No overlap by default
scale = 10  # 10m resolution

# Training parameters (Google Embedding)
model_type = 'AdvancedReferenceHeightMLP'  # Optimized for embedding features
hidden_dims = [1024, 512, 256, 128, 64]  # Deep architecture
epochs = 100  # Sufficient for convergence
batch_size = 32  # Memory-efficient training
learning_rate = 0.001  # Stable convergence

# Traditional satellite parameters (fallback)
bands_satellite = 30  # Original Sentinel-1/2, DEM, climate
bands_temporal = 196  # 12-month time series
bands_non_temporal = 31  # Median composites
```

## Project Structure

```
CHM_Image/
‚îú‚îÄ‚îÄ üìÅ Core Pipeline
‚îÇ   ‚îú‚îÄ‚îÄ chm_main.py                 # Google Earth Engine data collection
‚îÇ   ‚îú‚îÄ‚îÄ extract_gedi_with_embedding.py # Google Earth Engine data collection
‚îÇ   ‚îú‚îÄ‚îÄ train_predict_map.py        # Unified training and prediction system
‚îÇ   ‚îú‚îÄ‚îÄ predict.py                  # Primary prediction tool with mosaicking
‚îÇ   ‚îî‚îÄ‚îÄ run_main.py                 # Legacy main workflow
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Data Processing
‚îÇ   ‚îú‚îÄ‚îÄ data/                       # Data processing pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_patches.py        # 3D patch creation and management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalization.py        # Band-specific normalization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ large_area.py          # Scalable regional processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ multi_patch.py         # Multi-patch workflows
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ patch_loader.py        # Efficient data loading
‚îÇ   ‚îú‚îÄ‚îÄ alos2_source.py            # ALOS-2 SAR data processing
‚îÇ   ‚îú‚îÄ‚îÄ sentinel1_source.py        # Sentinel-1 SAR processing
‚îÇ   ‚îú‚îÄ‚îÄ sentinel2_source.py        # Sentinel-2 optical processing
‚îÇ   ‚îú‚îÄ‚îÄ l2a_gedi_source.py         # GEDI LiDAR data handling
‚îÇ   ‚îî‚îÄ‚îÄ dem_source.py              # DEM processing utilities
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Models and Training
‚îÇ   ‚îú‚îÄ‚îÄ models/                     # Model architectures
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 3d_unet.py             # Primary 3D U-Net architecture
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unet_3d.py             # Alternative 3D U-Net
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainers/              # Model-specific trainers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ losses/                # Loss function implementations
‚îÇ   ‚îú‚îÄ‚îÄ dl_models.py               # MLP and traditional models
‚îÇ   ‚îî‚îÄ‚îÄ training/                  # Modular training system (future)
‚îÇ       ‚îú‚îÄ‚îÄ core/                  # Base training infrastructure
‚îÇ       ‚îú‚îÄ‚îÄ data/                  # Data handling and augmentation
‚îÇ       ‚îî‚îÄ‚îÄ workflows/             # High-level training workflows
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Evaluation and Utilities
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_google_embedding_scenario1.py # Metrics calculation
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_google_embedding_scenario2a.py # Metrics calculation
‚îÇ   ‚îú‚îÄ‚îÄ create_simplified_prediction_visualizations.py # Visualization
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_predictions.py    # Legacy metrics calculation
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_temporal_results.py # Legacy Comprehensive PDF evaluation
‚îÇ   ‚îú‚îÄ‚îÄ save_evaluation_pdf.py     # Legacy report generation
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Core utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ spatial_utils.py       # Enhanced spatial processing
‚îÇ   ‚îú‚îÄ‚îÄ config/                    # Configuration management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ resolution_config.py   # Multi-resolution support
‚îÇ   ‚îî‚îÄ‚îÄ raster_utils.py           # Raster processing utilities
‚îÇ
‚îú‚îÄ‚îÄ üìÅ HPC Batch Processing (Google Embedding Experiments)
‚îÇ   ‚îî‚îÄ‚îÄ sbatch/                    # SLURM batch scripts for HPC execution
‚îÇ       ‚îú‚îÄ‚îÄ üì• Data Collection
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ extract_embedding_patches_all_areas.sh    # Extract 64-band embedding patches (all 3 regions)
‚îÇ       ‚îú‚îÄ‚îÄ üèãÔ∏è Training Scripts (Scenarios 1-5)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ train_google_embedding_scenario1.sh       # S1: Reference-only MLP (R¬≤ = 0.8734)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ train_google_embedding_scenario1_5.sh     # S1.5: GEDI-only U-Net (prerequisite for S2A)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ train_google_embedding_scenario2a.sh      # S2A: Reference+GEDI ensemble (R¬≤ = 0.7844)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ train_gedi_pixel_mlp_scenario4.sh         # S4: GEDI pixel MLP (R¬≤ = 0.1284)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ train_ensemble_scenario5.sh               # S5: Best ensemble model (R¬≤ = 0.7762)
‚îÇ       ‚îú‚îÄ‚îÄ üîÆ Prediction & Evaluation
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ evaluate_google_embedding_scenario1.sh    # S1 cross-region predictions
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ evaluate_google_embedding_scenario2a.sh   # S2A cross-region predictions
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ evaluate_gedi_pixel_scenario4.sh          # S4 cross-region predictions
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ evaluate_gedi_scenario5.sh                # S5 cross-region predictions
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ compare_all_scenarios.sh                  # Multi-scenario performance analysis
‚îÇ       ‚îî‚îÄ‚îÄ üìä Visualization Generation
‚îÇ           ‚îú‚îÄ‚îÄ create_simplified_visualizations.sh       # Multi-scenario comparison plots
‚îÇ           ‚îî‚îÄ‚îÄ create_gedi_scenario5_visualizations.sh   # GEDI ensemble specific outputs
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Development Files
‚îÇ   ‚îî‚îÄ‚îÄ docs/                      # Comprehensive documentation
‚îÇ       ‚îú‚îÄ‚îÄ docs/comprehensive_chm_experiment_summary.md
‚îÇ       ‚îî‚îÄ‚îÄ docs/gedi_pixel_extraction_and_evaluation_plan.md
‚îÇ
‚îî‚îÄ‚îÄ üìÅ Configuration
    ‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
    ‚îî‚îÄ‚îÄ .gitignore                 # Git configuration
```

### Key Features by Directory

#### üå≤ **Shift-Aware Training**: GEDI geolocation compensation with 88.0% improvement
#### üó∫Ô∏è **Comprehensive Mosaicking**: 75.8% coverage with 63-patch processing  
#### ü§ñ **Automatic Mode Detection**: Temporal vs non-temporal based on band patterns  
#### üéØ **Sparse GEDI Supervision**: <0.3% pixel coverage handled efficiently
#### üîÑ **Intelligent Fallbacks**: 3D U-Net falls back to temporal averaging when needed
#### üìä **Production Ready**: Fully documented and tested pipeline

## Dependencies

### Core Requirements
- **Python 3.10.0+** (tested with Python 3.10.0)
- **Google Earth Engine Python API** (earthengine-api)
- **PyTorch** (for U-Net models with CUDA support)
- **Rasterio** (geospatial raster processing)
- **NumPy & Pandas** (data processing)
- **scikit-learn** (RF/MLP models)

### Specialized Libraries  
- **rasterio[merge]** (spatial mosaicking)
- **geopandas** (vector data handling)
- **matplotlib & reportlab** (evaluation reports)
- **tqdm** (progress bars)
- **shapely** (geometric operations)

### GPU Requirements
- **CUDA-enabled PyTorch**: **ESSENTIAL** for efficient training and prediction
  - **Training**: Google Embedding models require GPU for reasonable training times (10 min vs 2+ hours on CPU)
  - **Prediction**: Cross-region prediction benefits significantly from GPU acceleration


### Optional Enhancements
- **Mixed precision training** (automatic mixed precision support for faster training)


## Data Requirements

### Input Data
- **Area of Interest (AOI)**: GeoJSON format defining study area
- **Google Satellite Embedding v1**: 64-band multi-modal embedding via Google Earth Engine (`GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL`)
- **GEDI L2A**: Sparse LiDAR heights for training/validation (<0.3% coverage)
- **Reference CHM**: Ground truth data for evaluation
- **Auxiliary Height Products**: Global canopy height datasets (Potapov2021, Tolan2024, Lang2022, Pauls2024)

### Satellite Data (via Google Earth Engine)

**ü•á Google Satellite Embedding v1 (RECOMMENDED):**
- **Data Source**: `GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL`
- **Features**: 64 bands (A00-A63) combining multiple satellite sources
- **Resolution**: 10m, pre-normalized [-1, 1] range
- **Components**: Sentinel-1/2, DEM, ALOS2, GEDI, ERA5, land cover
- **Usage**: `--band-selection embedding` or `--embedding-mode`
- **Performance**: R¬≤ = 0.8734 (73% improvement over traditional approaches)

**ü•à Traditional Satellite Data (Fallback):**
- **Sentinel-1**: C-band SAR (VV & VH polarizations)
  - Non-temporal: Median composite (2 bands)
  - Temporal: 12-month time series (24 bands)
- **Sentinel-2**: Optical imagery (10 bands + NDVI)
  - Non-temporal: Cloud-free composite (11 bands)  
  - Temporal: Monthly composites (132 bands)
- **ALOS-2**: L-band SAR data
  - Non-temporal: Median composite (2 bands)
  - Temporal: 12-month series (24 bands)
- **DEM**: Elevation, slope, aspect (~5 bands)
- **Forest Mask**: Forest masking such as DW or NDVI


## Expected Output Structure
```
chm_outputs/
‚îú‚îÄ‚îÄ üèÜ Google Embedding Models (RECOMMENDED)
‚îÇ   ‚îú‚îÄ‚îÄ production_mlp_reference_embedding_best.pth        # Google Embedding MLP (R¬≤ = 0.8734)
‚îÇ   ‚îú‚îÄ‚îÄ gedi_scenario5_ensemble/ensemble_mlp_best.pth      # GEDI Ensemble (R¬≤ = 0.7762)
‚îÇ   ‚îú‚îÄ‚îÄ google_embedding_scenario2a/        
‚îÇ   ‚îÇ     ‚îú‚îÄ‚îÄ ensemble_model/ensemble_mlp_best.pth         # Ensemble 2A (R¬≤ = 0.7844)
‚îÇ   ‚îÇ     ‚îî‚îÄ‚îÄ gedi_unet_model/shift_aware_unet_r2.pth
‚îÇ   ‚îî‚îÄ‚îÄ gedi_pixel_mlp_scenario4/                          # GEDI Pixel Model (R¬≤ = 0.1284)
‚îÇ         ‚îî‚îÄ‚îÄ gedi_pixel_mlp_scenario4_embedding_best.pth
‚îú‚îÄ‚îÄ üìä Predictions
‚îÇ   ‚îú‚îÄ‚îÄ google_embedding_scenario1_predictions/            # Best individual model predictions
‚îÇ   ‚îú‚îÄ‚îÄ gedi_scenario5_predictions/                        # Best ensemble predictions  
‚îÇ   ‚îú‚îÄ‚îÄ google_embedding_scenario2a_predictions/           # Stable ensemble predictions
‚îÇ   ‚îî‚îÄ‚îÄ cross_region_predictions/                          # Traditional 30-band predictions
‚îú‚îÄ‚îÄ üìà Evaluation & Visualization
‚îÇ   ‚îú‚îÄ‚îÄ simplified_prediction_visualizations/              # Multi-scenario comparisons
‚îÇ   ‚îî‚îÄ‚îÄ gedi_scenario5_visualizations/                     # GEDI ensemble visualizations
‚îú‚îÄ‚îÄ üîß Traditional Models (Fallback)
‚îÇ   ‚îî‚îÄ‚îÄ production_mlp_best.pth                           # Original 30-band MLP
‚îî‚îÄ‚îÄ üìÅ Extracted data (Image patches and csv) through GEE
    ‚îú‚îÄ‚îÄ dchm_{region_id}_bandNum*.tif                     # Patch TIF files for 30 bands + GEDI
    ‚îú‚îÄ‚îÄ dchm_{region_id}_embedding_bandNum*.tif           # Patch TIF files for google embedding
    ‚îî‚îÄ‚îÄ gedi_embedding_dchm_{region_id}*.csv              # GEDI pixel data with google embedding
       ‚îî‚îÄ‚îÄ*with_reference.csv                             # Add reference_heights by `analysis/add_reference_heights.py`
```

## üìä **Performance Comparison Summary**

| Approach | Data Type | Training R¬≤ | Cross-Region R¬≤ | Status | Key Advantage |
|----------|-----------|-------------|-----------------|--------|---------------|
| **Google Embedding Scenario 1** | 64-band | **0.8734** | -1.68 | ‚úÖ Outstanding | Maximum training accuracy |
| **GEDI Scenario 5 Ensemble** | 64-band | **0.7762** | **-0.66 to -2.57** | ‚úÖ **Best Cross-Region** | Automated ensemble learning |
| **Google Embedding Ensemble 2A** | 64-band | 0.7844 | -0.91 to -3.12 | ‚úÖ Proven | Most consistent correlations |
| **GEDI Scenario 4 (Pixel)** | 64-band | 0.1284 | -0.39 to -1.32 | ‚ö†Ô∏è Mixed | Better RMSE, challenging correlations |
| **Original 30-band MLP** | 30-band | 0.5026 | -26.58 | ‚úÖ Production | Proven baseline with bias correction |
| **Shift-Aware U-Net** | Various | N/A | N/A | ‚úÖ Alternative | 88% improvement for specific use cases |

### üìà **Cross-Region Generalization**
- **Best Immediate Deployment**: Global products (Potapov2021: R¬≤ = -0.39 to -0.55)
- **Best with Local Training**: Our models (GEDI Scenario 5: R¬≤ = 0.7762 training, -0.66 to -2.57 cross-region)
- **Key Finding**: Our models excel with training data; global products better for immediate cross-region deployment
- **Bias Correction**: Essential for cross-region deployment (Kochi: 2.5x, Tochigi: 3.7x factors)


## Legacy Code
### Traditional 4-Step Pipeline
```bash
# Use 10 pixel overlap which is defaults
python chm_main.py --aoi downloads/dchm_05LE4.geojson --year 2022 --use-patches --export-patches
# Use 20 pixel overlap
# python chm_main.py --aoi downloads/dchm_05LE4.geojson --year 2022 --use-patches --export-patches --patch-overlap 20
```

```bash
# Complete workflow with area of interest
python run_main.py \
  --aoi_path downloads/dchm_09gd4.geojson \
  --year 2022 \
  --eval_tif_path downloads/dchm_09gd4.tif \
  --use-patches \
  --patch-size 2560 \
  --model 3d_unet \
  --steps data_preparation height_analysis train_predict evaluate

# Temporal mode (Paul's 2025 methodology)
python run_main.py --temporal-mode --monthly-composite median --steps data_preparation
```

### Unified Patch-Based Training
```bash
# Shift-aware U-Net (RECOMMENDED - best performance)
python train_predict_map.py \
  --patch-dir "chm_outputs/" \
  --model shift_aware_unet \
  --output-dir chm_outputs/shift_aware_results \
  --shift-radius 2 \
  --epochs 50 \
  --learning-rate 0.0001 \
  --batch-size 2 \
  --generate-prediction

# Traditional Random Forest
python train_predict_map.py \
  --patch-path "chm_outputs/dchm_09gd4_bandNum31_scale10_patch0000.tif" \
  --model rf \
  --output-dir chm_outputs/rf_results

# Temporal 3D U-Net with data augmentation
python train_predict_map.py \
  --patch-path "chm_outputs/dchm_09gd4_temporal_bandNum196_scale10_patch0000.tif" \
  --model 3d_unet \
  --output-dir chm_outputs/3d_unet_results \
  --augment \
  --early-stopping-patience 15 \
  --generate-prediction
```

### Multi-Patch Processing
```bash
# Process all patches in a directory
python train_predict_map.py \
  --patch-dir "chm_outputs/" \
  --model-path "chm_outputs/2d_unet/best_model.pth" \
  --model 2d_unet \
  --mode predict \
  --generate-prediction

# Create spatial mosaic from predictions
python predict.py \
  --patch-dir "chm_outputs/" \
  --model-path "chm_outputs/3d_unet/final_model.pth" \
  --output-path "chm_outputs/merged_prediction.tif"
```

### Workflow Steps with Legacy code
#### 1. Data Preparation
```bash
python run_main.py --steps data_preparation
```
- Downloads satellite data from Google Earth Engine
- Processes multi-temporal Sentinel-1, Sentinel-2, and ALOS-2 data
- Creates forest mask using WorldCover data
- Exports patch-based training data with automatic temporal/non-temporal detection

#### 2. Height Analysis  
```bash
python run_main.py --steps height_analysis
```
- Combines GEDI height data with satellite features
- Analyzes temporal patterns and height distributions
- Generates comprehensive height statistics

#### 3. Training and Prediction
```bash
python run_main.py --steps train_predict
```
- Unified training for all model types (RF, MLP, 2D U-Net, 3D U-Net)
- Automatic temporal/non-temporal mode detection
- Enhanced training with data augmentation and early stopping
- Generates full spatial prediction maps

#### 4. Evaluation
```bash
python run_main.py --steps evaluate
```
- Comprehensive model performance evaluation
- Height-stratified analysis (critical for tall tree performance)
- Multi-page PDF reports with visualizations
- Feature importance and spatial distribution analysis


## License

This project is licensed under the MIT License - see the LICENSE file for details.